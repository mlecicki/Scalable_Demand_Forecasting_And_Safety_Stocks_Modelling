---
title: "Scalable Demand Forecasting and Safety Stock Modelling using Forecast Error"
author: "Maciej Lecicki"
date: "24 10 2021"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, include = TRUE, message = FALSE, warning = FALSE, fig.width = 12, fig.height = 6, fig.pos = 'H')
```

<br/>
<br/>
<br/>

### Purpose and objectives
<br/>

The purpose of this project is to illustrate how to develop robust demand forecasting model based on time series analysis and machine learning in R environment. <br/>

Important goal of this project is to show: <br/>
- potential of open source software like R for demand forecasting,<br/>
- scalability of this approach, namely ease of forecasting automation for multiple products/regions,<br/>
- ability to shape model selection criteria using common and customized metrics,<br/>
- focus on forecast error and confidence intervals as input to scenario planning for supply planning or S&OP process,<br/>
- use of forecast error as 'demand uncertainty' part of Safety Stock calculation.



##### Libraries and data
<br/>
```{r}
library('tidyverse')
library('tidymodels')
library('modeltime')
library('timetk')
library('lubridate')
library('workflowsets')
library('tune')
library('patchwork')
```

Key libraries used in this project are modeltime and tidymodels, both based on 'tidyverse' principles.

```{r}
data <- read_csv('data/elecsupply.csv')
glimpse(data)
range(data$date)
```

Dataset consist of monthly demand for electrical supply for 12 European countries collected between 1990 and 2003.

Let's change table format from wide to long and visualize demand.

```{r}
(elecsupply <- data %>%
  gather(country, elec_demand, Belgium:UK) %>%
  mutate(date = as_date(date, format = '%d.%m.%Y')) %>%
  relocate(country)
)

```

For demand visalization we could use plot_time_series() function (code is included as comments) from timetk package. It provides interactive element and has other advantages too, however I prefer 'good old' gglot2 which I find more elegant alternative if interaction isn't necessary.

```{r}
# elecsupply %>%
#   group_by(country) %>%
#   plot_time_series(date, elec_demand, .facet_ncol = 4, .smooth = FALSE)

elecsupply %>%
  ggplot(aes(x = date, y = elec_demand, group = country, color = country)) +
      geom_line(show.legend = FALSE) +
      theme_minimal() +
  facet_wrap(. ~ country, ncol = 3, scales = 'free_y') +
  geom_smooth(method = 'lm', se = FALSE, show.legend = FALSE)
```

With quick glance at all plots we can tell that demand is seasonal and there's upward trend in demand for electrical supply.

<br/>
##### Time series modelling
<br/>

The goal we'd like to achieve is development of best fit demand forecast using available resources in R.
The challenge is that we'd like to automate this process and do it at scale, meaning that we'd like to develop best models for all countries.
<br/>

To do that, we'll use modeltime package supported by tidymodels and tidyverse.
Let's start by describing high level the process and list key steps.<br/>

1. Dataset will be split into train and test:<br/>
 - train will be used to build the model,<br/>
 - testset of 24 months will be used to validate acccuracy and select best model,<br/>
 - in addition, test will be used to evaluate expected error that can be cascaded to Safety Stock calculation and scenario planning,<br/>
2. We'll also expand dataset by 12 months to forecast demand for electrical supply using best model.
3. We'll explore 'classic' time series approach and machine learning to develop demand forecasting model,<br/>
4. We'll look into available error metrics and enrich them by custom metrics.<br/>

Findings at each step of the process will be visualized using ggplot2. This can also be used as input to Shiny web app (if required to be shared with user that doesn't have access to R environment).


##### Train, test and future datasets

```{r}
nested_data_tbl <- elecsupply %>%
  group_by(country) %>%
  extend_timeseries(
    .id_var = country,
    .date_var = date,
    .length_future = 12 # this will be our forecasting horizon (in months)
  ) %>%
  nest_timeseries(
    .id_var = country,
    .length_future = 12
  ) %>%
  split_nested_timeseries(
    .length_test = 24 # test dataset (periods are months)
  )

nested_data_tbl
```

Actual and future data is nested inside newly created object and grouped by country. In addition we have information about split for train and test sets.<br/>

To get inside nested data we can use unnest() function from tidyr library. Example is shown below.
I encourage to also run commented code to see the difference in output.

```{r}
nested_data_tbl %>%
  filter(country == 'Denmark') %>%
  unnest(.actual_data) %>%
  select(country:elec_demand)

# nested_data_tbl %>%
#   filter(country == 'Denmark') %>%
#   unnest(.actual_data)
```

Nesting data in a form of tibble is very convenient and helpful from the point of view of model scalability. This concept will be used heavily in this project.


##### Time series modelling

<br/>


First, we'll build demand forecasting model using Machine Learning. Functions from modeltime library will be used in conjunction with tidymodels package.<br/>



Machine Learning based models don't recognize date based information, hence we need to recode date into 'ML friendly' calendar based qualitative features. Before that, to follow tidymodels standard we'll prepare recipe used in the model.<br/>
There's also a few other important steps taken in below code related to data pre-processing. All steps have relevant comments.

```{r}
rec_xgb <- recipe(elec_demand ~ ., extract_nested_train_split(nested_data_tbl)) %>%
  step_timeseries_signature(date) %>% # create dummy calendar features based on date
  step_rm(date) %>% # remove date column - not require anymore
  step_zv(all_predictors()) %>% # remove zero value predictors (if there are any)
  step_dummy(all_nominal(), one_hot = TRUE) # dummy predictors that are character data
```


We can check our recipe using bake() formula.

```{r}
bake(prep(rec_xgb), extract_nested_train_split(nested_data_tbl))
```

We can see that step_series_signature() formula created many calendar features and ALL of them have been passed to recipe.<br/>
At this point we could at a question if we need all of them and if all of them make sense taking into account granularity (frequency) of original date and its format (1st day of the month, month and year) or would they rather confuse our machine learning model?<br/>
I think it's the latter and therefore let's narrow features to correct ones taking into above.<br/>

TO BE CONTINUED.

```{r}

```





